{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uxdp35Ww_HgM"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acLexQVM61BJ"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dZuH65K61BK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, \n",
    "                 lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, \n",
    "                 token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, \n",
    "                 vocabulary=None, binary=False, dtype=np.float64, norm='l2', use_idf=True, smooth_idf=True, \n",
    "                 sublinear_tf=False):\n",
    "        if (tokenizer == None):\n",
    "            self._tokenizer = word_tokenize\n",
    "        else:\n",
    "            self._tokenizer = tokenizer\n",
    "        \n",
    "        self._vectorizer = TfidfVectorizer(\n",
    "            input=input, encoding=encoding, decode_error=decode_error, strip_accents=strip_accents, \n",
    "            lowercase=lowercase, preprocessor=preprocessor, tokenizer=self._tokenizer, analyzer=analyzer, \n",
    "            stop_words=stop_words, token_pattern=token_pattern, ngram_range=ngram_range, \n",
    "            max_df=max_df, min_df=min_df, max_features=max_features, vocabulary=vocabulary, binary=binary, \n",
    "            dtype=dtype, norm=norm, use_idf=use_idf, smooth_idf=smooth_idf, sublinear_tf=sublinear_tf)\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self._vectorizer.fit(self.optional_preprocess(df))\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        return self._vectorizer.fit_transform(self.optional_preprocess(df))\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Vectorize Pandas DataFrame\n",
    "        \"\"\"\n",
    "        return self._vectorizer.transform(self.optional_preprocess(df))\n",
    "    \n",
    "    def optional_preprocess(self, df):\n",
    "        return df.apply(lambda q: re.sub('[cC]\\+\\+', 'cpp', q))\n",
    "    \n",
    "    def save(self, file_name):\n",
    "        print(\"Saving model to \", file_name)\n",
    "        return joblib.dump(self, file_name)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load(file_name):\n",
    "        if (isinstance(file_name, str) and os.path.isfile(file_name)):\n",
    "            self = joblib.load(file_name)\n",
    "        else:\n",
    "            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), file_name)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwffwwRT61BW"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "RwM1UqZu61BX",
    "outputId": "9795e34d-8d07-4cdf-fb8d-90d4c0d64f7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>apply</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Mình muốn hỏi template hàm có ứng dụng gì tron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>other</td>\n",
       "      <td>general</td>\n",
       "      <td>thông tin covid19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>help</td>\n",
       "      <td>general</td>\n",
       "      <td>mình có thắc mắc không biết hỏi ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tip</td>\n",
       "      <td>cpp</td>\n",
       "      <td>có mẹo gì hay về C++ không?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>define</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Namespace trong C++ là gì?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>references</td>\n",
       "      <td>general</td>\n",
       "      <td>cho mình xin tài liệu học lập trình</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>define</td>\n",
       "      <td>general</td>\n",
       "      <td>Ý nghĩa của \"vptr\" trong hàm ảo là gì?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>disagree</td>\n",
       "      <td>general</td>\n",
       "      <td>codebot nhầm rồi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>help</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Chào codebot, mình đang đau đầu vì C++ đây</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>references</td>\n",
       "      <td>general</td>\n",
       "      <td>cho xin tài liệu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>define</td>\n",
       "      <td>cpp</td>\n",
       "      <td>Tôi muốn biết encapsulation trong C++ là gì?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>define</td>\n",
       "      <td>general</td>\n",
       "      <td>Const function là gì?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>agree</td>\n",
       "      <td>general</td>\n",
       "      <td>ừa hehe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>compare</td>\n",
       "      <td>general</td>\n",
       "      <td>Hãy phân biệt Syntax error và Runtime error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>references</td>\n",
       "      <td>cpp</td>\n",
       "      <td>có tài liệu C++ không?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         intent  context                                           question\n",
       "51        apply      cpp  Mình muốn hỏi template hàm có ứng dụng gì tron...\n",
       "304       other  general                                  thông tin covid19\n",
       "260        help  general                 mình có thắc mắc không biết hỏi ai\n",
       "341         tip      cpp                        có mẹo gì hay về C++ không?\n",
       "149      define      cpp                         Namespace trong C++ là gì?\n",
       "325  references  general                cho mình xin tài liệu học lập trình\n",
       "186      define  general             Ý nghĩa của \"vptr\" trong hàm ảo là gì?\n",
       "189    disagree  general                                   codebot nhầm rồi\n",
       "240        help      cpp         Chào codebot, mình đang đau đầu vì C++ đây\n",
       "337  references  general                                   cho xin tài liệu\n",
       "153      define      cpp       Tôi muốn biết encapsulation trong C++ là gì?\n",
       "173      define  general                              Const function là gì?\n",
       "42        agree  general                                            ừa hehe\n",
       "104     compare  general        Hãy phân biệt Syntax error và Runtime error\n",
       "318  references      cpp                             có tài liệu C++ không?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (os.path.basename(os.getcwd()) != \"CodEbot\"):\n",
    "    os.chdir('../')\n",
    "\n",
    "data = pd.read_csv(\"./data/data.csv\")\n",
    "\n",
    "X = data.question\n",
    "y = data[[\"intent\", \"context\"]]\n",
    "\n",
    "data.sample(frac=1).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Programming Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      cậu biết ý tớ đó\n",
       "1            câu trả lời thật là bổ ích\n",
       "2       câu trả lời thật là bổ ích đó ạ\n",
       "3                           chắc là vậy\n",
       "4                              chắc thế\n",
       "                     ...               \n",
       "1067                               mau;\n",
       "1068                           cout<<ps\n",
       "1069                        tu<<”/”<<ps\n",
       "1070                              mau; \n",
       "1071                                   \n",
       "Length: 1072, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = './data/programming_corpus'\n",
    "corpus = [X]\n",
    "for name in ['Array_Char_String_Struct_Cpp', 'Ham_For_While', 'c++']:\n",
    "    with open(f'{corpus_path}/{name}.txt', 'r', encoding='utf-8') as f:\n",
    "        tmp = list(filter(lambda s: len(s) , f.read()[1:].replace('.', '\\n').split('\\n')))\n",
    "        corpus.append(pd.Series(tmp))\n",
    "\n",
    "tfidf_data = pd.concat(corpus, ignore_index=True)\n",
    "tfidf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the preprocessing model with dataset and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaph\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  \"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to  ./src/codebot/model/preprocessing_1.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./src/codebot/model/preprocessing_1.bin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf__ngram_range = (1, 2)\n",
    "tfidf__max_df = 1.0\n",
    "tfidf__min_df = 3\n",
    "\n",
    "preprocessor = Preprocessing(ngram_range=tfidf__ngram_range, max_df=tfidf__max_df, min_df=tfidf__min_df)\n",
    "preprocessor.fit(tfidf_data)\n",
    "\n",
    "preprocessor.save(\"./src/codebot/model/preprocessing_1.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvDVzL8DCg8d"
   },
   "source": [
    "# Intent Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADcu5K3NE30p"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMdwdhJrE4Iz"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPJiqsUl61Cw"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2NNRIiK61Cy"
   },
   "outputs": [],
   "source": [
    "def micro_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Preprocessing.load(\"./src/codebot/model/preprocessing_1.bin\")\n",
    "\n",
    "X_processed = pre.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xOV1VKmI61B1",
    "outputId": "2e9a82be-0421-4c8e-aaed-4b8bc68049fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro f1_score of TRAIN_intent: 0.9928825622775801\n",
      "\n",
      "classification_report of TRAIN_intent:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       1.00      0.95      0.97        37\n",
      "       apply       1.00      1.00      1.00        26\n",
      "     compare       1.00      1.00      1.00        26\n",
      " credit_info       1.00      1.00      1.00        19\n",
      "      define       1.00      1.00      1.00        41\n",
      "    disagree       1.00      1.00      1.00        25\n",
      "    greeting       1.00      1.00      1.00        14\n",
      "        help       1.00      1.00      1.00        27\n",
      "       other       0.95      1.00      0.97        35\n",
      "  references       1.00      1.00      1.00        21\n",
      "         tip       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.99       281\n",
      "   macro avg       1.00      1.00      0.99       281\n",
      "weighted avg       0.99      0.99      0.99       281\n",
      "\n",
      "micro f1_score of TEST_intent: 0.8732394366197183\n",
      "\n",
      "classification_report of TEST_intent:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       1.00      0.67      0.80         9\n",
      "       apply       0.88      1.00      0.93         7\n",
      "     compare       1.00      1.00      1.00         6\n",
      " credit_info       1.00      0.40      0.57         5\n",
      "      define       0.85      1.00      0.92        11\n",
      "    disagree       0.70      1.00      0.82         7\n",
      "    greeting       0.75      1.00      0.86         3\n",
      "        help       1.00      0.86      0.92         7\n",
      "       other       0.78      0.78      0.78         9\n",
      "  references       1.00      1.00      1.00         5\n",
      "         tip       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.87        71\n",
      "   macro avg       0.90      0.88      0.87        71\n",
      "weighted avg       0.90      0.87      0.87        71\n",
      "\n",
      "micro f1_score of TRAIN_context: 1.0\n",
      "\n",
      "classification_report of TRAIN_context:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cpp       1.00      1.00      1.00        72\n",
      "     general       1.00      1.00      1.00       209\n",
      "\n",
      "    accuracy                           1.00       281\n",
      "   macro avg       1.00      1.00      1.00       281\n",
      "weighted avg       1.00      1.00      1.00       281\n",
      "\n",
      "micro f1_score of TEST_context: 0.9859154929577465\n",
      "\n",
      "classification_report of TEST_context:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cpp       1.00      0.94      0.97        18\n",
      "     general       0.98      1.00      0.99        53\n",
      "\n",
      "    accuracy                           0.99        71\n",
      "   macro avg       0.99      0.97      0.98        71\n",
      "weighted avg       0.99      0.99      0.99        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = {\n",
    "    \"intent\": 0.5,\n",
    "    \"context\": 100\n",
    "}\n",
    "\n",
    "for column in [\"intent\", \"context\"]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_processed, y[column], test_size=0.2, random_state=46,stratify=y[column])\n",
    "    \n",
    "    model = LinearSVC(C=C[column], random_state=46)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"micro f1_score of TRAIN_{column}: {micro_f1_score(pred, y_train)}\\n\")\n",
    "    print(f\"classification_report of TRAIN_{column}:\\n{classification_report(y_train, pred, labels=model.classes_)}\")\n",
    "    print(f\"micro f1_score of TEST_{column}: {micro_f1_score(pred_test, y_test)}\\n\")\n",
    "    print(f\"classification_report of TEST_{column}:\\n{classification_report(y_test, pred_test, labels=model.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGEL12lX61DL"
   },
   "source": [
    "## Retrain & Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xi0Zdcqo61DM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score of AllData_intent: 0.9914772727272727\n",
      "f1_score of AllData_context: 1.0\n"
     ]
    }
   ],
   "source": [
    "for column in [\"intent\", \"context\"]:\n",
    "    model = LinearSVC(C=C[column], random_state=46)\n",
    "    model.fit(X_processed, y[column])\n",
    "\n",
    "    pred = model.predict(X_processed)\n",
    "\n",
    "    print(f\"f1_score of AllData_{column}: {micro_f1_score(pred, y[column])}\")\n",
    "    \n",
    "    joblib.dump(model, f\"./src/codebot/model/model_{column}_1.bin\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CodEbot.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
